<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://mathworks.github.io/arrow-site/arrow-site/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mathworks.github.io/arrow-site/arrow-site/" rel="alternate" type="text/html" /><updated>2024-05-30T11:48:53-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/feed.xml</id><title type="html">Apache Arrow</title><subtitle>Apache Arrow is a cross-language development platform for in-memory data. It specifies a standardized language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware. It also provides computational libraries and zero-copy streaming messaging and interprocess communication. Languages currently supported include C, C++, C#, Go, Java, JavaScript, MATLAB, Python, R, Ruby, and Rust.</subtitle><entry><title type="html">Apache Arrow nanoarrow 0.5.0 Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/27/nanoarrow-0.5.0-release/" rel="alternate" type="text/html" title="Apache Arrow nanoarrow 0.5.0 Release" /><published>2024-05-27T00:00:00-04:00</published><updated>2024-05-27T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/27/nanoarrow-0.5.0-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/27/nanoarrow-0.5.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 0.5.0 release of
Apache Arrow nanoarrow. This release covers 79 resolved issues from
9 contributors.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>The primary focus of the nanoarrow 0.5.0 release was expanding the
initial <a href="#python-bindings">Python bindings</a> that were released in 0.4.0.
The nanoarrow Python package can now create and consume most Arrow
data types, arrays, and array streams, including conversion to/from
objects compatible with the Python buffer protocol and conversion
to/from lists of Python objects.</p>

<p>The nanoarrow 0.5.0 release also includes updates to its build
configuration to make it possible to use nanoarrow with <code class="language-plaintext highlighter-rouge">FetchContent</code>
in projects with a wider variety of CMake usage. In addition to CMake,
nanoarrow now supports the Meson build system. Thanks to
<a href="https://github.com/vyasr">@vyasr</a> and <a href="https://github.com/WillAyd">@WillAyd</a>
for contributing these changes!</p>

<p>In the <a href="#r-bindings">R bindings</a>, support for reading IPC streams
is now accessible with <code class="language-plaintext highlighter-rouge">read_nanoarrow()</code>!</p>

<p>Finally, build system helpers and helpers to reconcile modern C++ usage
with nanorrow C structures (e.g., iterating over an <code class="language-plaintext highlighter-rouge">ArrowArrayStream</code> or
<code class="language-plaintext highlighter-rouge">ArrowArray</code> using a range-for loop) were added to <code class="language-plaintext highlighter-rouge">nanoarrow.hpp</code>.
Thanks to <a href="https://github.com/bkietz">@bkeitz</a> for contributing these
changes!</p>

<p>See the
<a href="https://github.com/apache/arrow-nanoarrow/blob/apache-arrow-nanoarrow-0.5.0/CHANGELOG.md">Changelog</a>
for a detailed list of contributions to this release.</p>

<h2 id="breaking-changes">Breaking Changes</h2>

<p>Most changes included in the nanoarrow 0.5.0 release will not break downstream
code; however, several changes in the C library are breaking changes to previous
behaviour.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ArrowBufferResize()</code> and <code class="language-plaintext highlighter-rouge">ArrowBitmapResize()</code> now adjust <code class="language-plaintext highlighter-rouge">size_bytes</code>/
<code class="language-plaintext highlighter-rouge">size_bits</code> in addition to <code class="language-plaintext highlighter-rouge">capacity_bytes</code>/<code class="language-plaintext highlighter-rouge">buffer.capacity_bytes</code>.
Preivously these functions only adjusted the capacity of the underlying
buffer which caused some understandable confusion even though this
behaviour was documented. This change affects all usage of
<code class="language-plaintext highlighter-rouge">ArrowBufferReisze()</code> and <code class="language-plaintext highlighter-rouge">ArrowBitmapResize()</code> that <em>increased</em> the size
of the underlying buffer (i.e., usage where <code class="language-plaintext highlighter-rouge">shrink_to_fit</code> was non zero
should be unaffected).</li>
  <li><code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code> now <em>always</em> calls the allocator’s <code class="language-plaintext highlighter-rouge">free()</code> callback.
Previously, a call to the <code class="language-plaintext highlighter-rouge">free()</code> callback was skipped if the pointer was
<code class="language-plaintext highlighter-rouge">NULL</code>; however, this led to some confusion and made it easy to accidentally
leak a custom deallocator whose pointer happened to be <code class="language-plaintext highlighter-rouge">NULL</code>.</li>
  <li>As a consequence of the above, it is now mandatory to call <code class="language-plaintext highlighter-rouge">ArrowBufferInit()</code>
before calling <code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code>. There was some existing usage of nanoarrow
that zero-ed the memory for an <code class="language-plaintext highlighter-rouge">ArrowBuffer</code> and then (sometimes) called
<code class="language-plaintext highlighter-rouge">ArrowBufferReset()</code>. Preivously this was a no-op; however, after 0.5.0 this
will crash. This is consistent with other structures in the nanoarrow C library
(which require an initialization before it is safe to reset/release them).</li>
</ul>

<h3 id="python-bindings">Python bindings</h3>

<p>The nanoarrow Python bindings are distributed as the <code class="language-plaintext highlighter-rouge">nanoarrow</code> package on
<a href="https://pypi.org/project/nanoarrow/">PyPI</a> and <a href="https://anaconda.org/conda-forge/nanoarrow">conda-forge</a>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>nanoarrow
conda <span class="nb">install </span>nanoarrow <span class="nt">-c</span> conda-forge
</code></pre></div></div>

<p>High level users can use the <code class="language-plaintext highlighter-rouge">Schema</code>, <code class="language-plaintext highlighter-rouge">Array</code>, and <code class="language-plaintext highlighter-rouge">ArrayStream</code> classes
to interact with data types, arrays, and array streams:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">nanoarrow</span> <span class="k">as</span> <span class="n">na</span>

<span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">()</span>
<span class="c1">#&gt; &lt;Schema&gt; int32
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">())</span>
<span class="c1">#&gt; nanoarrow.Array&lt;int32&gt;[3]
#&gt; 1
#&gt; 2
#&gt; 3
</span>
<span class="n">url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows</span><span class="sh">"</span>
<span class="n">na</span><span class="p">.</span><span class="n">ArrayStream</span><span class="p">.</span><span class="nf">from_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="c1">#&gt; nanoarrow.ArrayStream&lt;non-nullable struct&lt;commit: string, time: timestamp('us', 'UTC'), files: int3...&gt;
</span></code></pre></div></div>

<p>Low-level users can use <code class="language-plaintext highlighter-rouge">c_schema()</code>, <code class="language-plaintext highlighter-rouge">c_array()</code>, and <code class="language-plaintext highlighter-rouge">c_array_stream()</code> to interact
with thin wrappers around the Arrow C Data interface structures:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">na</span><span class="p">.</span><span class="nf">c_schema</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">decimal128</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1">#&gt; &lt;nanoarrow.c_schema.CSchema decimal128(10, 3)&gt;
#&gt; - format: 'd:10,3'
#&gt; - name: ''
#&gt; - flags: 2
#&gt; - metadata: NULL
#&gt; - dictionary: NULL
#&gt; - children[0]:
</span>
<span class="n">na</span><span class="p">.</span><span class="nf">c_array</span><span class="p">([</span><span class="sh">"</span><span class="s">one</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">two</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">three</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">string</span><span class="p">())</span>
<span class="c1">#&gt; &lt;nanoarrow.c_array.CArray string&gt;
#&gt; - length: 4
#&gt; - offset: 0
#&gt; - null_count: 1
#&gt; - buffers: (4754305168, 4754307808, 4754310464)
#&gt; - dictionary: NULL
#&gt; - children[0]:
</span></code></pre></div></div>

<p>All nanoarrow type/array-like objects implement the
<a href="https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html">Arrow PyCapsule interface</a>
for both producing and consuming and are zero-copy interchangeable with <code class="language-plaintext highlighter-rouge">pyarrow</code>
objects in many cases:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyarrow</span> <span class="k">as</span> <span class="n">pa</span>

<span class="n">pa</span><span class="p">.</span><span class="nf">field</span><span class="p">(</span><span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">())</span>
<span class="c1">#&gt; pyarrow.Field&lt;: int32&gt;
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Schema</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">string</span><span class="p">())</span>
<span class="c1">#&gt; &lt;Schema&gt; string
</span>
<span class="n">pa</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">na</span><span class="p">.</span><span class="nf">int32</span><span class="p">()))</span>
<span class="c1">#&gt; &lt;pyarrow.lib.Int32Array object at 0x11b552500&gt;
#&gt; [
#&gt;   4,
#&gt;   5,
#&gt;   6
#&gt; ]
</span>
<span class="n">na</span><span class="p">.</span><span class="nc">Array</span><span class="p">(</span><span class="n">pa</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]))</span>
<span class="c1">#&gt; nanoarrow.Array&lt;int64&gt;[3]
#&gt; 10
#&gt; 11
#&gt; 12
</span></code></pre></div></div>

<p>For a more detailed tour of the nanoarrow Python bindings, see the
<a href="https://arrow.apache.org/nanoarrow/latest/getting-started/python.html">Getting started in Python guide</a> and the
<a href="https://arrow.apache.org/nanoarrow/latest/reference/python/index.html">Python API reference</a>.</p>

<h3 id="cc">C/C++</h3>

<p>The nanoarrow 0.5.0 release includes a number of bugfixes and improvements
to the core C library and C++ helpers.</p>

<p>First, the CMake build system was refactored to enable <code class="language-plaintext highlighter-rouge">FetchContent</code> to
work in a wider variety of
<a href="https://github.com/apache/arrow-nanoarrow/tree/main/examples/cmake-scenarios">develop/build/install scenarios</a>. In most cases, CMake-based projects should be able
to add the nanoarrow C library as a dependency with:</p>

<div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">include</span><span class="p">(</span>FetchContent<span class="p">)</span>
<span class="nf">fetchcontent_declare</span><span class="p">(</span>nanoarrow
                     GIT_REPOSITORY https://github.com/apache/arrow-nanoarrow.git
                     GIT_TAG  apache-arrow-nanoarrow-0.5.0
                     GIT_SHALLOW TRUE<span class="p">)</span>
<span class="nf">fetchcontent_makeavailable</span><span class="p">(</span>nanoarrow<span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span>some_target ...<span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>some_target nanoarrow::nanoarrow<span class="p">)</span>
</code></pre></div></div>

<p>Projects using the <a href="https://mesonbuild.com/">Meson</a> build system can install
nanoarrow from <a href="https://mesonbuild.com/Wrapdb-projects.html">WrapDB</a> using:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> subprojects
meson wrap <span class="nb">install </span>nanoarrow
</code></pre></div></div>

<p>…and use <code class="language-plaintext highlighter-rouge">dependency('nanoarrow')</code> to add the dependency:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nanoarrow_dep = dependency('nanoarrow')
example_exec = executable('some_target',
                          ...,
                          dependencies: [nanoarrow_dep])
</code></pre></div></div>

<p>Finally, a set of C++ range/view helpers were added to smooth out some
of more verbose aspects of working with nanoarrow in C++. While the
new helpers are targeted at more than just nanoarrow’s tests, they have been
particularly helpful in allowing nanoarrow’s tests to be more less repetitive
and more effective. For example, one particularly verbose test was collapsed
to:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;gtest/gtest.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;gmock/gmock-matchers.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;nanoarrow/nanoarrow_gtest_util.hpp&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;nanoarrow/nanoarrow.hpp&gt;</span><span class="cp">
</span>
<span class="n">nanoarrow</span><span class="o">::</span><span class="n">UniqueArrayStream</span> <span class="n">array_stream</span><span class="p">;</span>
<span class="c1">// ... populate array_stream</span>
<span class="n">nanoarrow</span><span class="o">::</span><span class="n">ViewArrayStream</span> <span class="nf">array_stream_view</span><span class="p">(</span><span class="n">array_stream</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>

<span class="k">for</span> <span class="p">(</span><span class="n">ArrowArray</span><span class="o">&amp;</span> <span class="n">array</span> <span class="o">:</span> <span class="n">array_stream_view</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">EXPECT_THAT</span><span class="p">(</span><span class="n">nanoarrow</span><span class="o">::</span><span class="n">ViewArrayAs</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">array</span><span class="p">),</span> <span class="n">ElementsAre</span><span class="p">(</span><span class="mi">1234</span><span class="p">));</span>
<span class="p">}</span>

<span class="n">EXPECT_EQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">count</span><span class="p">(),</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">EXPECT_EQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">code</span><span class="p">(),</span> <span class="n">NANOARROW_OK</span><span class="p">);</span>
<span class="n">EXPECT_STREQ</span><span class="p">(</span><span class="n">array_stream_view</span><span class="p">.</span><span class="n">error</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">message</span><span class="p">,</span> <span class="s">""</span><span class="p">);</span>
</code></pre></div></div>

<p>See the new section in the
<a href="https://arrow.apache.org/nanoarrow/latest/reference/cpp.html#range-for-utilities">C++ API reference</a> for details.</p>

<h3 id="r-bindings">R bindings</h3>

<p>The nanoarrow R bindings are distributed as the <code class="language-plaintext highlighter-rouge">nanoarrow</code> package on
<a href="https://cran.r-project.org/">CRAN</a>.</p>

<p>Whereas nanoarrow has had an IPC reader supporting most features of the
IPC streaming format since 0.3.0, the R bindings did not implement bindings
until this release. The 0.5.0 release of the R package includes <code class="language-plaintext highlighter-rouge">read_nanoarrow()</code>
as an entrypoint to reading streams from various sources including URLs,
filenames, and R connections:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">url</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows"</span><span class="w">

</span><span class="n">read_nanoarrow</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">tibble</span><span class="o">::</span><span class="n">as_tibble</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; # A tibble: 15,487 × 5</span><span class="w">
</span><span class="c1">#&gt;    commit                                time                files merge message</span><span class="w">
</span><span class="c1">#&gt;    &lt;chr&gt;                                 &lt;dttm&gt;              &lt;int&gt; &lt;lgl&gt; &lt;chr&gt;</span><span class="w">
</span><span class="c1">#&gt;  1 49cdb0fe4e98fda19031c864a18e6156c6ed… 2024-03-07 02:00:52     2 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  2 1d966e98e41ce817d1f8c5159c0b9caa4de7… 2024-03-06 21:51:34     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  3 96f26a89bd73997f7532643cdb27d04b7097… 2024-03-06 20:29:15     1 FALSE GH-402…</span><span class="w">
</span><span class="c1">#&gt;  4 ee1a8c39a55f3543a82fed900dadca791f6e… 2024-03-06 07:46:45     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  5 3d467ac7bfae03cf2db09807054c5672e195… 2024-03-05 16:13:32     1 FALSE GH-201…</span><span class="w">
</span><span class="c1">#&gt;  6 ef6ea6beed071ed070daf03508f4c14b4072… 2024-03-05 14:53:13    20 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt;  7 53e0c745ad491af98a5bf18b67541b12d779… 2024-03-05 12:31:38     2 FALSE GH-401…</span><span class="w">
</span><span class="c1">#&gt;  8 3ba6d286caad328b8572a3b9228045da8c8d… 2024-03-05 08:15:42     6 FALSE GH-400…</span><span class="w">
</span><span class="c1">#&gt;  9 4ce9a5edd2710fb8bf0c642fd0e3863b01c2… 2024-03-05 07:56:25     2 FALSE GH-401…</span><span class="w">
</span><span class="c1">#&gt; 10 2445975162905bd8d9a42ffc9cd0daa0e19d… 2024-03-05 01:04:20     1 FALSE GH-403…</span><span class="w">
</span><span class="c1">#&gt; # ℹ 15,477 more rows</span><span class="w">
</span></code></pre></div></div>

<p>In developing the Python bindings, it became clear that a representation of
a Arrow C++’s <code class="language-plaintext highlighter-rouge">ChunkedArray</code> was an important concept to represent. Whereas
the Python bindings have the <code class="language-plaintext highlighter-rouge">Array</code> class to provide this structure, the
R bindings had only the <code class="language-plaintext highlighter-rouge">nanoarrow_array</code> as a thin wrapper around the
Arrow C Data interface. When developing the geospatial extension
<a href="https://github.com/geoarrow/geoarrow-r">GeoArrow for R</a>, a data structure that
maintained chunked Arrow memory as an R vector was needed as an intermediary
between an Arrow-native source and an R-native destination. This experimental
structure can be created with <code class="language-plaintext highlighter-rouge">as_nanoarrow_vctr()</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">nanoarrow</span><span class="p">)</span><span class="w">

</span><span class="n">array</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as_nanoarrow_array</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"one"</span><span class="p">,</span><span class="w"> </span><span class="s2">"two"</span><span class="p">,</span><span class="w"> </span><span class="s2">"three"</span><span class="p">))</span><span class="w">
</span><span class="n">convert_array</span><span class="p">(</span><span class="n">array</span><span class="p">,</span><span class="w"> </span><span class="n">nanoarrow_vctr</span><span class="p">())</span><span class="w">
</span><span class="c1">#&gt; &lt;nanoarrow_vctr string[3]&gt;</span><span class="w">
</span><span class="c1">#&gt; [1] "one"   "two"   "three"</span><span class="w">
</span></code></pre></div></div>

<h2 id="contributors">Contributors</h2>

<p>This release consists of contributions from 9 contributors in addition
to the invaluable advice and support of the Apache Arrow developer mailing list.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>git shortlog <span class="nt">-sn</span> apache-arrow-nanoarrow-0.5.0.dev..apache-arrow-nanoarrow-0.5.0 | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s2">"GitHub Actions"</span>
<span class="go">  67  Dewey Dunnington
  3  Dirk Eddelbuettel
  3  Joris Van den Bossche
  2  William Ayd
  1  Alenka Frim
  1  Benjamin Kietzman
  1  Max Conradt
  1  Vyas Ramasubramani
  1  eitsupi
</span></code></pre></div></div>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 0.5.0 release of Apache Arrow nanoarrow. This release covers 79 resolved issues from 9 contributors. Release Highlights The primary focus of the nanoarrow 0.5.0 release was expanding the initial Python bindings that were released in 0.4.0. The nanoarrow Python package can now create and consume most Arrow data types, arrays, and array streams, including conversion to/from objects compatible with the Python buffer protocol and conversion to/from lists of Python objects. The nanoarrow 0.5.0 release also includes updates to its build configuration to make it possible to use nanoarrow with FetchContent in projects with a wider variety of CMake usage. In addition to CMake, nanoarrow now supports the Meson build system. Thanks to @vyasr and @WillAyd for contributing these changes! In the R bindings, support for reading IPC streams is now accessible with read_nanoarrow()! Finally, build system helpers and helpers to reconcile modern C++ usage with nanorrow C structures (e.g., iterating over an ArrowArrayStream or ArrowArray using a range-for loop) were added to nanoarrow.hpp. Thanks to @bkeitz for contributing these changes! See the Changelog for a detailed list of contributions to this release. Breaking Changes Most changes included in the nanoarrow 0.5.0 release will not break downstream code; however, several changes in the C library are breaking changes to previous behaviour. ArrowBufferResize() and ArrowBitmapResize() now adjust size_bytes/ size_bits in addition to capacity_bytes/buffer.capacity_bytes. Preivously these functions only adjusted the capacity of the underlying buffer which caused some understandable confusion even though this behaviour was documented. This change affects all usage of ArrowBufferReisze() and ArrowBitmapResize() that increased the size of the underlying buffer (i.e., usage where shrink_to_fit was non zero should be unaffected). ArrowBufferReset() now always calls the allocator’s free() callback. Previously, a call to the free() callback was skipped if the pointer was NULL; however, this led to some confusion and made it easy to accidentally leak a custom deallocator whose pointer happened to be NULL. As a consequence of the above, it is now mandatory to call ArrowBufferInit() before calling ArrowBufferReset(). There was some existing usage of nanoarrow that zero-ed the memory for an ArrowBuffer and then (sometimes) called ArrowBufferReset(). Preivously this was a no-op; however, after 0.5.0 this will crash. This is consistent with other structures in the nanoarrow C library (which require an initialization before it is safe to reset/release them). Python bindings The nanoarrow Python bindings are distributed as the nanoarrow package on PyPI and conda-forge: pip install nanoarrow conda install nanoarrow -c conda-forge High level users can use the Schema, Array, and ArrayStream classes to interact with data types, arrays, and array streams: import nanoarrow as na na.int32() #&gt; &lt;Schema&gt; int32 na.Array([1, 2, 3], na.int32()) #&gt; nanoarrow.Array&lt;int32&gt;[3] #&gt; 1 #&gt; 2 #&gt; 3 url = "https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows" na.ArrayStream.from_url(url) #&gt; nanoarrow.ArrayStream&lt;non-nullable struct&lt;commit: string, time: timestamp('us', 'UTC'), files: int3...&gt; Low-level users can use c_schema(), c_array(), and c_array_stream() to interact with thin wrappers around the Arrow C Data interface structures: na.c_schema(pa.decimal128(10, 3)) #&gt; &lt;nanoarrow.c_schema.CSchema decimal128(10, 3)&gt; #&gt; - format: 'd:10,3' #&gt; - name: '' #&gt; - flags: 2 #&gt; - metadata: NULL #&gt; - dictionary: NULL #&gt; - children[0]: na.c_array(["one", "two", "three", None], na.string()) #&gt; &lt;nanoarrow.c_array.CArray string&gt; #&gt; - length: 4 #&gt; - offset: 0 #&gt; - null_count: 1 #&gt; - buffers: (4754305168, 4754307808, 4754310464) #&gt; - dictionary: NULL #&gt; - children[0]: All nanoarrow type/array-like objects implement the Arrow PyCapsule interface for both producing and consuming and are zero-copy interchangeable with pyarrow objects in many cases: import pyarrow as pa pa.field(na.int32()) #&gt; pyarrow.Field&lt;: int32&gt; na.Schema(pa.string()) #&gt; &lt;Schema&gt; string pa.array(na.Array([4, 5, 6], na.int32())) #&gt; &lt;pyarrow.lib.Int32Array object at 0x11b552500&gt; #&gt; [ #&gt; 4, #&gt; 5, #&gt; 6 #&gt; ] na.Array(pa.array([10, 11, 12])) #&gt; nanoarrow.Array&lt;int64&gt;[3] #&gt; 10 #&gt; 11 #&gt; 12 For a more detailed tour of the nanoarrow Python bindings, see the Getting started in Python guide and the Python API reference. C/C++ The nanoarrow 0.5.0 release includes a number of bugfixes and improvements to the core C library and C++ helpers. First, the CMake build system was refactored to enable FetchContent to work in a wider variety of develop/build/install scenarios. In most cases, CMake-based projects should be able to add the nanoarrow C library as a dependency with: include(FetchContent) fetchcontent_declare(nanoarrow GIT_REPOSITORY https://github.com/apache/arrow-nanoarrow.git GIT_TAG apache-arrow-nanoarrow-0.5.0 GIT_SHALLOW TRUE) fetchcontent_makeavailable(nanoarrow) add_executable(some_target ...) target_link_libraries(some_target nanoarrow::nanoarrow) Projects using the Meson build system can install nanoarrow from WrapDB using: mkdir -p subprojects meson wrap install nanoarrow …and use dependency('nanoarrow') to add the dependency: nanoarrow_dep = dependency('nanoarrow') example_exec = executable('some_target', ..., dependencies: [nanoarrow_dep]) Finally, a set of C++ range/view helpers were added to smooth out some of more verbose aspects of working with nanoarrow in C++. While the new helpers are targeted at more than just nanoarrow’s tests, they have been particularly helpful in allowing nanoarrow’s tests to be more less repetitive and more effective. For example, one particularly verbose test was collapsed to: #include &lt;gtest/gtest.h&gt; #include &lt;gmock/gmock-matchers.h&gt; #include &lt;nanoarrow/nanoarrow_gtest_util.hpp&gt; #include &lt;nanoarrow/nanoarrow.hpp&gt; nanoarrow::UniqueArrayStream array_stream; // ... populate array_stream nanoarrow::ViewArrayStream array_stream_view(array_stream.get()); for (ArrowArray&amp; array : array_stream_view) { EXPECT_THAT(nanoarrow::ViewArrayAs&lt;int32_t&gt;(&amp;array), ElementsAre(1234)); } EXPECT_EQ(array_stream_view.count(), 1); EXPECT_EQ(array_stream_view.code(), NANOARROW_OK); EXPECT_STREQ(array_stream_view.error()-&gt;message, ""); See the new section in the C++ API reference for details. R bindings The nanoarrow R bindings are distributed as the nanoarrow package on CRAN. Whereas nanoarrow has had an IPC reader supporting most features of the IPC streaming format since 0.3.0, the R bindings did not implement bindings until this release. The 0.5.0 release of the R package includes read_nanoarrow() as an entrypoint to reading streams from various sources including URLs, filenames, and R connections: library(nanoarrow) url &lt;- "https://github.com/apache/arrow-experiments/raw/main/data/arrow-commits/arrow-commits.arrows" read_nanoarrow(url) |&gt; tibble::as_tibble() #&gt; # A tibble: 15,487 × 5 #&gt; commit time files merge message #&gt; &lt;chr&gt; &lt;dttm&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; #&gt; 1 49cdb0fe4e98fda19031c864a18e6156c6ed… 2024-03-07 02:00:52 2 FALSE GH-403… #&gt; 2 1d966e98e41ce817d1f8c5159c0b9caa4de7… 2024-03-06 21:51:34 1 FALSE GH-403… #&gt; 3 96f26a89bd73997f7532643cdb27d04b7097… 2024-03-06 20:29:15 1 FALSE GH-402… #&gt; 4 ee1a8c39a55f3543a82fed900dadca791f6e… 2024-03-06 07:46:45 1 FALSE GH-403… #&gt; 5 3d467ac7bfae03cf2db09807054c5672e195… 2024-03-05 16:13:32 1 FALSE GH-201… #&gt; 6 ef6ea6beed071ed070daf03508f4c14b4072… 2024-03-05 14:53:13 20 FALSE GH-403… #&gt; 7 53e0c745ad491af98a5bf18b67541b12d779… 2024-03-05 12:31:38 2 FALSE GH-401… #&gt; 8 3ba6d286caad328b8572a3b9228045da8c8d… 2024-03-05 08:15:42 6 FALSE GH-400… #&gt; 9 4ce9a5edd2710fb8bf0c642fd0e3863b01c2… 2024-03-05 07:56:25 2 FALSE GH-401… #&gt; 10 2445975162905bd8d9a42ffc9cd0daa0e19d… 2024-03-05 01:04:20 1 FALSE GH-403… #&gt; # ℹ 15,477 more rows In developing the Python bindings, it became clear that a representation of a Arrow C++’s ChunkedArray was an important concept to represent. Whereas the Python bindings have the Array class to provide this structure, the R bindings had only the nanoarrow_array as a thin wrapper around the Arrow C Data interface. When developing the geospatial extension GeoArrow for R, a data structure that maintained chunked Arrow memory as an R vector was needed as an intermediary between an Arrow-native source and an R-native destination. This experimental structure can be created with as_nanoarrow_vctr(): library(nanoarrow) array &lt;- as_nanoarrow_array(c("one", "two", "three")) convert_array(array, nanoarrow_vctr()) #&gt; &lt;nanoarrow_vctr string[3]&gt; #&gt; [1] "one" "two" "three" Contributors This release consists of contributions from 9 contributors in addition to the invaluable advice and support of the Apache Arrow developer mailing list. $ git shortlog -sn apache-arrow-nanoarrow-0.5.0.dev..apache-arrow-nanoarrow-0.5.0 | grep -v "GitHub Actions" 67 Dewey Dunnington 3 Dirk Eddelbuettel 3 Joris Van den Bossche 2 William Ayd 1 Alenka Frim 1 Benjamin Kietzman 1 Max Conradt 1 Vyas Ramasubramani 1 eitsupi]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 12 (Libraries) Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/21/adbc-12-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 12 (Libraries) Release" /><published>2024-05-21T00:00:00-04:00</published><updated>2024-05-21T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/21/adbc-12-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/21/adbc-12-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 12th release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/16"><strong>56
resolved issues</strong></a> from <a href="#contributors"><strong>13 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version 12.
The <strong>API specification</strong> is versioned separately and is at
version 1.1.0.</p>

<p>The subcomponents are versioned independently:</p>

<ul>
  <li>C/C++/GLib/Go/Python/Ruby: 1.0.0</li>
  <li>C#: 0.12.0</li>
  <li>Java: 0.12.0</li>
  <li>R: 0.12.0</li>
  <li>Rust: 0.12.0</li>
</ul>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-12/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>There is a <a href="https://github.com/apache/arrow-adbc/issues/1841">known issue</a>
with multiple drivers in a single process due to using languages with runtimes
as the basis for many drivers.</p>

<p>Option strings in C# are now case-sensitive.  In general, the C# bindings are
rapidly progressing.  A driver that wraps the Hive Thrift API was added.</p>

<p>The Flight SQL driver now supports the new “stateless” prepared statement
proposal.</p>

<p>Rust libraries were not released to Cargo, but the implementation has made
rapid progress.</p>

<p>The Snowflake driver now supports bind parameters.  Also, some queries which
only return JSON data (e.g. <code class="language-plaintext highlighter-rouge">SHOW TABLES</code>) are now supported.  Quoting of
names in bulk ingestion was fixed to conform to Snowflake SQL syntax.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.11.0..apache-arrow-adbc-12
    25	David Li
    19	Curt Hagenlocher
     5	Matt Topol
     5	Sutou Kouhei
     4	Dewey Dunnington
     3	Alexandre Crayssac
     3	Matthijs Brobbel
     2	Bruce Irschick
     2	Cocoa
     2	davidhcoe
     1	Bryce Mecum
     1	Hyunseok Seo
     1	Joel Lubinitsky
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>A Google BigQuery driver is being developed in Go.  We anticipate C# will
reach stability soon and Rust should start seeing releases as well.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/arrow-site/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 12th release of the Apache Arrow ADBC libraries. This covers includes 56 resolved issues from 13 distinct contributors. This is a release of the libraries, which are at version 12. The API specification is versioned separately and is at version 1.1.0. The subcomponents are versioned independently: C/C++/GLib/Go/Python/Ruby: 1.0.0 C#: 0.12.0 Java: 0.12.0 R: 0.12.0 Rust: 0.12.0 The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights There is a known issue with multiple drivers in a single process due to using languages with runtimes as the basis for many drivers. Option strings in C# are now case-sensitive. In general, the C# bindings are rapidly progressing. A driver that wraps the Hive Thrift API was added. The Flight SQL driver now supports the new “stateless” prepared statement proposal. Rust libraries were not released to Cargo, but the implementation has made rapid progress. The Snowflake driver now supports bind parameters. Also, some queries which only return JSON data (e.g. SHOW TABLES) are now supported. Quoting of names in bulk ingestion was fixed to conform to Snowflake SQL syntax. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.11.0..apache-arrow-adbc-12 25 David Li 19 Curt Hagenlocher 5 Matt Topol 5 Sutou Kouhei 4 Dewey Dunnington 3 Alexandre Crayssac 3 Matthijs Brobbel 2 Bruce Irschick 2 Cocoa 2 davidhcoe 1 Bryce Mecum 1 Hyunseok Seo 1 Joel Lubinitsky Roadmap A Google BigQuery driver is being developed in Go. We anticipate C# will reach stability soon and Rust should start seeing releases as well. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 16.1.0 Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/14/16.1.0-release/" rel="alternate" type="text/html" title="Apache Arrow 16.1.0 Release" /><published>2024-05-14T00:00:00-04:00</published><updated>2024-05-14T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/14/16.1.0-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/14/16.1.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 16.1.0 release.
This is a minor release that includes <a href="https://github.com/apache/arrow/milestone/63?closed=1"><strong>34 resolved issues</strong></a>
from <a href="/arrow-site/release/16.1.0.html#contributors"><strong>16 distinct contributors</strong></a>. See the Install Page to learn how to get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Other bugfixes and improvements have been made: we refer
you to the <a href="/arrow-site/release/16.1.0.html#changelog">complete changelog</a>.</p>

<h2 id="c-notes">C++ notes</h2>

<p>The scratch space required by some <code class="language-plaintext highlighter-rouge">Scalar</code> subclasses is now immutable after
initialization (<a href="https://github.com/apache/arrow/issues/40069">GH-40069</a>). This fixes thread-safety bugs when this scratch
space was lazily initialized, but introduces an API incompatibility because
writing to the <code class="language-plaintext highlighter-rouge">value</code> member of some concrete <code class="language-plaintext highlighter-rouge">Scalar</code> subclasses is not
allowed anymore. Affected classes include <code class="language-plaintext highlighter-rouge">BaseBinaryScalar</code>, <code class="language-plaintext highlighter-rouge">BaseListScalar</code>,
<code class="language-plaintext highlighter-rouge">SparseUnionScalar</code>, <code class="language-plaintext highlighter-rouge">DenseUnionScalar</code> and <code class="language-plaintext highlighter-rouge">RunEndEncodedScalar</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">bit_width</code> and <code class="language-plaintext highlighter-rouge">byte_width</code> methods on <code class="language-plaintext highlighter-rouge">ExtensionType</code> now return the
corresponding value for the underlying storage type (<a href="https://github.com/apache/arrow/issues/41353">GH-41353</a>).</p>

<h3 id="parquet">Parquet</h3>

<p>A regression that prevented reading BYTE_STREAM_SPLIT columns with null values
was fixed (<a href="https://github.com/apache/arrow/issues/41562">GH-41562</a>).</p>

<h2 id="c-notes-1">C# notes</h2>
<ul>
  <li>Recompute a sliced array’s null count on demand when it is unknown (<a href="https://github.com/apache/arrow/issues/41136">GH-41136</a>)</li>
  <li>Support writing sliced arrays in the Arrow IPC format (<a href="https://github.com/apache/arrow/issues/40517">GH-40517</a>, <a href="https://github.com/apache/arrow/issues/41225">GH-41225</a>, <a href="https://github.com/apache/arrow/issues/41231">GH-41231</a>)</li>
  <li>Bug fixes for union array behaviour (<a href="https://github.com/apache/arrow/issues/41137">GH-41137</a>, <a href="https://github.com/apache/arrow/issues/41140">GH-41140</a>)</li>
</ul>

<h2 id="go-notes">Go Notes</h2>

<ul>
  <li>Enable support for reading date64 from CSV (<a href="https://github.com/apache/arrow/issues/41594">GH-41594</a>)</li>
  <li>Update MarshalJSON() for Float32 and Float64 to be able to handle NaN, +Inf and -Inf values (<a href="https://github.com/apache/arrow/issues/40563">GH-40563</a>)</li>
</ul>

<h2 id="javascript-notes">JavaScript notes</h2>

<ul>
  <li>Store Timestamps in 64 bits (<a href="https://github.com/apache/arrow/issues/40959">GH-40959</a>)</li>
  <li>Update JS dependencies (<a href="https://github.com/apache/arrow/issues/40989">GH-40989</a>)</li>
  <li>Add at() for array like types (<a href="https://github.com/apache/arrow/issues/39131">GH-39131</a>)</li>
  <li>Refactor imports (<a href="https://github.com/apache/arrow/issues/39482">GH-39482</a>)</li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 16.1.0 release. This is a minor release that includes 34 resolved issues from 16 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Other bugfixes and improvements have been made: we refer you to the complete changelog. C++ notes The scratch space required by some Scalar subclasses is now immutable after initialization (GH-40069). This fixes thread-safety bugs when this scratch space was lazily initialized, but introduces an API incompatibility because writing to the value member of some concrete Scalar subclasses is not allowed anymore. Affected classes include BaseBinaryScalar, BaseListScalar, SparseUnionScalar, DenseUnionScalar and RunEndEncodedScalar. The bit_width and byte_width methods on ExtensionType now return the corresponding value for the underlying storage type (GH-41353). Parquet A regression that prevented reading BYTE_STREAM_SPLIT columns with null values was fixed (GH-41562). C# notes Recompute a sliced array’s null count on demand when it is unknown (GH-41136) Support writing sliced arrays in the Arrow IPC format (GH-40517, GH-41225, GH-41231) Bug fixes for union array behaviour (GH-41137, GH-41140) Go Notes Enable support for reading date64 from CSV (GH-41594) Update MarshalJSON() for Float32 and Float64 to be able to handle NaN, +Inf and -Inf values (GH-40563) JavaScript notes Store Timestamps in 64 bits (GH-40959) Update JS dependencies (GH-40989) Add at() for array like types (GH-39131) Refactor imports (GH-39482)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Announcing Apache Arrow DataFusion is now Apache DataFusion</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/07/datafusion-tlp/" rel="alternate" type="text/html" title="Announcing Apache Arrow DataFusion is now Apache DataFusion" /><published>2024-05-07T00:00:00-04:00</published><updated>2024-05-07T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/07/datafusion-tlp</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/05/07/datafusion-tlp/"><![CDATA[<!--

-->

<h2 id="introduction">Introduction</h2>

<p>TLDR; <a href="https://arrow.apache.org/">Apache Arrow</a> DataFusion –&gt; <a href="https://datafusion.apache.org/">Apache DataFusion</a></p>

<p>The Arrow PMC and newly created DataFusion PMC are happy to announce that as of
April 16, 2024 the Apache Arrow DataFusion subproject is now a top level
<a href="https://www.apache.org/">Apache Software Foundation</a> project.</p>

<h2 id="background">Background</h2>

<p>Apache DataFusion is a fast, extensible query engine for building high-quality
data-centric systems in Rust, using the Apache Arrow in-memory format.</p>

<p>When DataFusion was <a href="https://arrow.apache.org/blog/2019/02/04/datafusion-donation/">donated to the Apache Software Foundation</a> in 2019, the
DataFusion community was not large enough to stand on its own and the Arrow
project agreed to help support it. The community has grown significantly since
2019, benefiting immensely from being part of Arrow and following <a href="https://www.apache.org/theapacheway/">The Apache
Way</a>.</p>

<h2 id="why-now">Why now?</h2>

<p>The community <a href="https://github.com/apache/datafusion/discussions/6475">discussed graduating to a top level project publicly</a> for almost
a year, as the project seemed ready to stand on its own and would benefit from
more focused governance. For example, earlier in DataFusion’s life many
contributed to both <a href="https://github.com/apache/arrow-rs">arrow-rs</a> and DataFusion, but as DataFusion has matured many
contributors, committers and PMC members focused more and more exclusively on
DataFusion.</p>

<h2 id="looking-forward">Looking forward</h2>

<p>The future looks bright. There are now <a href="https://datafusion.apache.org/user-guide/introduction.html#known-users">10s of known projects built with
DataFusion</a>, and that number continues to grow. We recently held our <a href="https://github.com/apache/datafusion/discussions/8522">first in
person meetup</a> passed <a href="https://github.com/apache/datafusion/stargazers">5000 stars</a> on GitHub, <a href="https://github.com/apache/datafusion/issues/8373#issuecomment-2025133714">wrote a paper that was accepted
at SIGMOD 2024</a>, and began work on <a href="https://github.com/apache/datafusion-comet">Comet</a>, an <a href="https://spark.apache.org/">Apache Spark</a> accelerator
<a href="https://arrow.apache.org/blog/2024/03/06/comet-donation/">initially donated by Apple</a>.</p>

<p>Thank you to everyone in the Arrow community who helped DataFusion grow and
mature over the years, and we look forward to continuing our collaboration as
projects. All future blogs and announcements will be posted on the <a href="https://datafusion.apache.org/">Apache
DataFusion</a> website.</p>

<h2 id="get-involved">Get Involved</h2>

<p>If you are interested in joining the community, we would love to have you join
us. Get in touch using <a href="https://datafusion.apache.org/contributor-guide/communication.html">Communication Doc</a> and learn how to get involved in the
<a href="https://datafusion.apache.org/contributor-guide/index.html">Contributor Guide</a>. We welcome everyone to try DataFusion on their
own data and projects and let us know how it goes, contribute suggestions,
documentation, bug reports, or a PR with documentation, tests or code.</p>]]></content><author><name>pmc</name></author><category term="subprojects" /><summary type="html"><![CDATA[Introduction TLDR; Apache Arrow DataFusion –&gt; Apache DataFusion The Arrow PMC and newly created DataFusion PMC are happy to announce that as of April 16, 2024 the Apache Arrow DataFusion subproject is now a top level Apache Software Foundation project. Background Apache DataFusion is a fast, extensible query engine for building high-quality data-centric systems in Rust, using the Apache Arrow in-memory format. When DataFusion was donated to the Apache Software Foundation in 2019, the DataFusion community was not large enough to stand on its own and the Arrow project agreed to help support it. The community has grown significantly since 2019, benefiting immensely from being part of Arrow and following The Apache Way. Why now? The community discussed graduating to a top level project publicly for almost a year, as the project seemed ready to stand on its own and would benefit from more focused governance. For example, earlier in DataFusion’s life many contributed to both arrow-rs and DataFusion, but as DataFusion has matured many contributors, committers and PMC members focused more and more exclusively on DataFusion. Looking forward The future looks bright. There are now 10s of known projects built with DataFusion, and that number continues to grow. We recently held our first in person meetup passed 5000 stars on GitHub, wrote a paper that was accepted at SIGMOD 2024, and began work on Comet, an Apache Spark accelerator initially donated by Apple. Thank you to everyone in the Arrow community who helped DataFusion grow and mature over the years, and we look forward to continuing our collaboration as projects. All future blogs and announcements will be posted on the Apache DataFusion website. Get Involved If you are interested in joining the community, we would love to have you join us. Get in touch using Communication Doc and learn how to get involved in the Contributor Guide. We welcome everyone to try DataFusion on their own data and projects and let us know how it goes, contribute suggestions, documentation, bug reports, or a PR with documentation, tests or code.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 16.0.0 Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/04/20/16.0.0-release/" rel="alternate" type="text/html" title="Apache Arrow 16.0.0 Release" /><published>2024-04-20T00:00:00-04:00</published><updated>2024-04-20T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/04/20/16.0.0-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/04/20/16.0.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 16.0.0 release. This covers
over 3 months of development work and includes <a href="https://github.com/apache/arrow/milestone/59?closed=1"><strong>385 resolved issues</strong></a>
on <a href="/arrow-site/release/16.0.0.html#contributors"><strong>586 distinct commits</strong></a> from <a href="/arrow-site/release/16.0.0.html#contributors"><strong>119 distinct contributors</strong></a>.
See the <a href="https://arrow.apache.org/install/">Install Page</a>
to learn how to get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Many other bugfixes and improvements have been made: we refer
you to the <a href="/arrow-site/release/16.0.0.html#changelog">complete changelog</a>.</p>

<h2 id="community">Community</h2>

<p>Since the 15.0.0 release, Jeffrey Vo, Jay Zhan, Bryce Mecum, Joel Lubinitsky,
and Sarah Gilmore have been invited to be committers.
No new members have joined the Project Management Committee (PMC).</p>

<p>Thanks for your contributions and participation in the project!</p>

<h2 id="c-data-interface-notes">C Data Interface notes</h2>

<ul>
  <li>Added <code class="language-plaintext highlighter-rouge">RegisterDeviceMemoryManager</code> and <code class="language-plaintext highlighter-rouge">GetDeviceMemoryManage</code> for managing mappings between a device type and id to a memory manager (<a href="https://github.com/apache/arrow/issues/40698">GH-40698</a>).</li>
  <li>Added <code class="language-plaintext highlighter-rouge">RegisterCUDADevice</code> to register CUDA devices (<a href="https://github.com/apache/arrow/issues/40698">GH-40698</a>).</li>
  <li>Added <code class="language-plaintext highlighter-rouge">ImportFromChunkedArray</code> and <code class="language-plaintext highlighter-rouge">ExportChunkedArray</code> for handling Chunked Arrays in the C Stream Interface (<a href="https://github.com/apache/arrow/issues/38717">GH-38717</a>).</li>
  <li>Fixed an issue where string and nested types weren’t being correctly imported with DeviceArray (<a href="https://github.com/apache/arrow/issues/39769">GH-39769</a>).</li>
  <li>Added support for copying Arrays and RecordBatches between memory types (<a href="https://github.com/apache/arrow/issues/39771">GH-39771</a>).</li>
</ul>

<h2 id="arrow-flight-rpc-notes">Arrow Flight RPC notes</h2>

<ul>
  <li>Session variable RPCs were added (<a href="https://github.com/apache/arrow/issues/34865">GH-34865</a>)</li>
  <li>Go: cookies can be copied to another connection to reuse existing credentials (<a href="https://github.com/apache/arrow/issues/39837">GH-39837</a>)</li>
  <li>Go: enable PollFlightInfo for Flight SQL clients/servers (<a href="https://github.com/apache/arrow/issues/39574">GH-39574</a>)</li>
  <li>Java: the JDBC driver now tries all locations the server sends it (<a href="https://github.com/apache/arrow/issues/38573">GH-38573</a>)</li>
  <li>Java: tweak some options to give better performance (<a href="https://github.com/apache/arrow/issues/40745">GH-40475</a>, <a href="https://github.com/apache/arrow/issues/40039">GH-40039</a>)</li>
</ul>

<h2 id="c-notes">C++ notes</h2>
<p>For C++ notes refer to the full changelog.</p>

<h3 id="highlights">Highlights</h3>

<ul>
  <li>Initial support for the Azure Blob Storage has been added (<a href="https://github.com/apache/arrow/issues/18014">GH-18014</a>).</li>
  <li>Arrow C++ can now be built with Emscripten (<a href="https://github.com/apache/arrow/pull/37821">GH-37821</a>) which lays the foundation for running Arrow C++ under WASM runtimes and eventually <a href="https://github.com/apache/arrow/pull/37822">PyArrow</a> as well.</li>
  <li>Arrow’s filesystem modules have been separated out into individual libraries and this change enables writing and registering custom filesystem implementations (<a href="https://github.com/apache/arrow/issues/38309">GH-38309</a>).</li>
  <li>Conversion from <code class="language-plaintext highlighter-rouge">Table</code> and <code class="language-plaintext highlighter-rouge">RecordBatch</code> to a <code class="language-plaintext highlighter-rouge">Tensor</code> (not the same as
<a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#official-list">tensor extension array</a>)
is being developed. Umbrella issue is created (<a href="https://github.com/apache/arrow/issues/40058">GH-40058</a>)
and issues connected to the <code class="language-plaintext highlighter-rouge">RecordBatch</code> conversion are included in this release
(<a href="https://github.com/apache/arrow/issues/40059">GH-40059</a>,
<a href="https://github.com/apache/arrow/issues/40357">GH-40357</a>,
<a href="https://github.com/apache/arrow/issues/40297">GH-40297</a>,
<a href="https://github.com/apache/arrow/issues/40060">GH-40060</a>,
<a href="https://github.com/apache/arrow/issues/40061">GH-40061</a> and
<a href="https://github.com/apache/arrow/issues/40866">GH-40866</a>) which means <code class="language-plaintext highlighter-rouge">RecordBatch</code> can now be
converted to a column or row-major two-dimensional structure.</li>
</ul>

<h3 id="compute">Compute</h3>

<h4 id="bug-fixes">Bug Fixes</h4>

<ul>
  <li>Fixed a potential crash when accessing the <code class="language-plaintext highlighter-rouge">true_count</code> property on a BooleanArray (<a href="https://github.com/apache/arrow/issues/41016">GH-41016</a>).</li>
</ul>

<h4 id="performance-improvements">Performance improvements</h4>

<ul>
  <li>Significantly improved performance of the take kernel on certain types of inputs (<a href="https://github.com/apache/arrow/issues/40207">GH-40207</a>).</li>
</ul>

<h4 id="enhancements">Enhancements</h4>

<ul>
  <li>Support for casting to and from half-float (float16) has been added (<a href="https://github.com/apache/arrow/issues/20213">GH-20213</a>).</li>
  <li>Added support for residual predicates to Swiss Join implementation (<a href="https://github.com/apache/arrow/issues/20339">GH-20339</a>).</li>
  <li>Expanded support to primitive filter implementation for all fixed-width primitive types and take filter implementation for all well-known fixed-width types (<a href="https://github.com/apache/arrow/issues/39740">GH-39740</a>).</li>
  <li>Added support for calling the <code class="language-plaintext highlighter-rouge">binary_slice</code> kernel on Fixed-Size Binary Arrays (<a href="https://github.com/apache/arrow/issues/39231">GH-39231</a>).</li>
  <li>The cast kernel now supports casting from LargeString, Binary, and LargeBinary to Dictionary (<a href="https://github.com/apache/arrow/issues/39463">GH-39463</a>).</li>
  <li>Fields of different decimal precision can now be used together in arithmetic operations without an explicit cast beforehand. (<a href="https://github.com/apache/arrow/issues/40126">GH-40126</a>).</li>
</ul>

<h3 id="datasets">Datasets</h3>

<ul>
  <li>Improved backpressure handling in the Dataset Writer which can significantly reduce memory usage for some use cases (<a href="https://github.com/apache/arrow/pull/40722">https://github.com/apache/arrow/pull/40722</a>).</li>
</ul>

<h3 id="parquet">Parquet</h3>

<ul>
  <li>Byte stream split encoding support has been added for FIXED_LEN_BYTE_ARRAY, INT32, and INT64 which enables this encoding for half-float (float16) and fixed-width decimal (<a href="https://github.com/apache/arrow/issues/39978">GH-39978</a>).</li>
  <li>Decoding boolean values has been made faster for a variety of cases (<a href="https://github.com/apache/arrow/issues/40872">GH-40872</a>).</li>
</ul>

<h3 id="filesystems">Filesystems</h3>

<h4 id="new-features">New Features</h4>

<ul>
  <li>In addition to building the individual filesystem implementations as separate modules, users can now write and register custom filesystem implementations (<a href="https://github.com/apache/arrow/issues/38309">GH-38309</a>).</li>
  <li>A new environment variable, <code class="language-plaintext highlighter-rouge">AWS_ENDPOINT_URL_S3</code>, has been added which allows separately overriding the endpoint for S3 operations alone (<a href="https://github.com/apache/arrow/issues/38663">GH-38663</a>).</li>
</ul>

<h4 id="bug-fixes-1">Bug Fixes</h4>

<ul>
  <li>Fixed a bug in the S3 filesystem implementation that could cause a crash when deleting an object having duplicate forward slashes in its name (<a href="https://github.com/apache/arrow/issues/38821">GH-38821</a>).</li>
  <li>Fixed a bug where <code class="language-plaintext highlighter-rouge">hash_mean</code> could silently overflow (<a href="https://github.com/apache/arrow/issues/38833">GH-38833</a>).</li>
</ul>

<h4 id="improvements">Improvements</h4>

<ul>
  <li>The S3 implementation now sets the content-type of directory-like objects to application/x-directory to improve compatibility with other S3 tools (<a href="https://github.com/apache/arrow/issues/38794">GH-38794</a>).</li>
  <li>Repeated S3Client initialization is now roughly an order of magnitude faster (<a href="https://github.com/apache/arrow/pull/40299">GH-40299</a>).</li>
  <li>The MemoryPoolStats implementation has been reworked to re-order loads and stores which may be an improvement for some allocation-heavy, multi-threaded applications (<a href="https://github.com/apache/arrow/issues/40783">GH-40783</a>).</li>
</ul>

<h3 id="substrait">Substrait</h3>

<ul>
  <li>Support has been added to Substrait for a variety of Arrow types (<a href="https://github.com/apache/arrow/issues/40695">GH-40695</a>).</li>
  <li>substrait-cpp has been upgraded to 0.44 (<a href="https://github.com/apache/arrow/issues/40695">GH-40695</a>).</li>
</ul>

<h3 id="development">Development</h3>

<ul>
  <li>Added support the mold and lld linkers for building Arrow C++ (<a href="https://github.com/apache/arrow/issues/40394">GH-40394</a>, <a href="https://github.com/apache/arrow/issues/40400">GH-40400</a>).</li>
</ul>

<h3 id="miscellaneous">Miscellaneous</h3>

<ul>
  <li>Upgraded ORC to 2.0.0 (<a href="https://github.com/apache/arrow/issues/40507">GH-40507</a>).</li>
  <li>Upgraded zstd to 1.5.6 (<a href="https://github.com/apache/arrow/pull/40837">GH-40837</a>).</li>
  <li>Upgraded google benchmark to 1.8.3 (<a href="https://github.com/apache/arrow/issues/39863">GH-39863</a>).</li>
  <li>Upgraded zlib 1.3.1 (<a href="https://github.com/apache/arrow/issues/39876">GH-39876</a>).</li>
  <li>Various ToString methods now support an optional <code class="language-plaintext highlighter-rouge">show_metadata</code> argument which will print metadata that may exist in nested types. (<a href="https://github.com/apache/arrow/issues/39864">GH-39864</a>).</li>
</ul>

<h2 id="c-notes-1">C# notes</h2>
<ul>
  <li>IPC record batch compression has been implemented <a href="https://github.com/apache/arrow/issues/24834">GH-24834</a></li>
  <li>Optional materialization of C# string arrays is now supported <a href="https://github.com/apache/arrow/issues/41047">GH-41047</a></li>
  <li>A memory leak in the C Data interface has been fixed <a href="https://github.com/apache/arrow/issues/40898">GH-40898</a></li>
  <li>Various other bug fixes and improvements.</li>
</ul>

<h2 id="go-notes">Go Notes</h2>

<ul>
  <li>The Golang Arrow and Parquet libraries now require Go 1.21+ (<a href="https://github.com/apache/arrow/issues/40733">GH-40733</a>)</li>
</ul>

<h3 id="bug-fixes-2">Bug Fixes</h3>

<h4 id="arrow">Arrow</h4>

<ul>
  <li>FlightSQL Driver will now properly handle concurrent result sets instead of pulling the entire result into memory (<a href="https://github.com/apache/arrow/issues/40089">GH-40089</a>)</li>
  <li>FlightSQL driver will now correctly respect the <code class="language-plaintext highlighter-rouge">DriverConfig.TLSEnabled</code> field (<a href="https://github.com/apache/arrow/issues/40097">GH-40097</a>)</li>
  <li>Fixed a panic on 32-bit architectures (<a href="https://github.com/apache/arrow/issues/40672">GH-40672</a>)</li>
  <li>Corrected a precision loss for Decimal types when converting to JSON (<a href="https://github.com/apache/arrow/issues/40693">GH-40693</a>)</li>
  <li>Fixed an issue with <code class="language-plaintext highlighter-rouge">array.RecordBuilder</code> when using a NullType column (<a href="https://github.com/apache/arrow/issues/40719">GH-40719</a>)</li>
</ul>

<h4 id="parquet-1">Parquet</h4>

<ul>
  <li>Fixed panic when writing a DeltaBinaryPacked column containing only nulls (<a href="https://github.com/apache/arrow/issues/35718">GH-35718</a>)</li>
  <li>Fixed a panic when writing a ListOf(DeltaBinaryPacked) field with no data (<a href="https://github.com/apache/arrow/issues/39309">GH-39309</a>)</li>
  <li>Arrow DATE64 types will now be properly coerced into Parquet DATE[32-bit] logical type (<a href="https://github.com/apache/arrow/issues/39456">GH-39456</a>)</li>
  <li>Fixed the timezone semantics for timestamp conversion from Arrow to Parquet (<a href="https://github.com/apache/arrow/issues/39466">GH-39466</a>)</li>
  <li>Corrected an inaccuracy with <code class="language-plaintext highlighter-rouge">RowGroupTotalCompressedBytes</code> and <code class="language-plaintext highlighter-rouge">RowGroupTotalBytesWritten</code> for Parquet file writer (<a href="https://github.com/apache/arrow/issues/39870">GH-39870</a>)</li>
  <li>Fixed the <code class="language-plaintext highlighter-rouge">TotalCompressedBytes</code> count when falling back to plain encoding if a dictionary is too large (<a href="https://github.com/apache/arrow/issues/39921">GH-39921</a>)</li>
  <li>Fixed a bug when reslicing a nullable dictionary in the chunked writer (<a href="https://github.com/apache/arrow/issues/39925">GH-39925</a>)</li>
</ul>

<h3 id="enhancements-1">Enhancements</h3>

<h4 id="arrow-1">Arrow</h4>

<ul>
  <li>Users can now access the underlying <code class="language-plaintext highlighter-rouge">MemoTable</code> of a dictionary builder (<a href="https://github.com/apache/arrow/issues/38988">GH-38988</a>)</li>
  <li>Added an option to provide a string replacer for CSV writing (<a href="https://github.com/apache/arrow/issues/39552">GH-39552</a>)</li>
  <li>Flight: Cookies can be copied to another connection to reuse existing credentials (<a href="https://github.com/apache/arrow/issues/39837">GH-39837</a>)</li>
  <li>Flight: enable PollFlightInfo for Flight SQL clients/servers (<a href="https://github.com/apache/arrow/issues/39574">GH-39574</a>)</li>
  <li>Added the ability to create a PreparedStatement from persisted data and provided access for FlightSQL users to the PreparedStatement handle property (<a href="https://github.com/apache/arrow/issues/39774">GH-39774</a> <a href="https://github.com/apache/arrow/issues/39910">GH-39910</a>)</li>
  <li>FlightRPC Session management extensions have been implemented (<a href="https://github.com/apache/arrow/issues/40155">GH-40155</a>)</li>
</ul>

<h4 id="parquet-2">Parquet</h4>

<ul>
  <li>Can now register new compression codecs for Parquet (<a href="https://github.com/apache/arrow/issues/40113">GH-40113</a>)</li>
  <li>Parquet footers can be incrementally written without closing the file (<a href="https://github.com/apache/arrow/issues/40630">GH-40630</a>)</li>
</ul>

<h2 id="java-notes">Java notes</h2>
<ul>
  <li>A breaking change to support Java 9 modules has been implemented in this release. <a href="https://github.com/apache/arrow/issues/39001">GH-39001</a></li>
  <li>A new Float16 type has been added. <a href="https://github.com/apache/arrow/issues/39680">GH-39680</a></li>
  <li>Java 22 is supported. <a href="https://github.com/apache/arrow/issues/40680">GH-40680</a></li>
  <li>Various bug fixes and improvements.</li>
</ul>

<h2 id="javascript-notes">JavaScript notes</h2>

<ul>
  <li>Dates are now stored as TimestampMillisecond
(<a href="https://github.com/apache/arrow/pull/40892">GH-40892</a>)</li>
  <li>Vectors created from typed arrays are now correctly not nullable and null
counts are now correct
(<a href="https://github.com/apache/arrow/pull/40852">GH-40852</a>)</li>
</ul>

<h2 id="python-notes">Python notes</h2>

<p>Compatibility notes:</p>
<ul>
  <li>To ensure PyArrow compatibility with NumPy 2.0 umbrella issue has been closed <a href="https://github.com/apache/arrow/issues/39532">GH-39532</a> with last issues included in 16.0.0 Arrow release (<a href="https://github.com/apache/arrow/issues/41098">GH-41098</a>, <a href="https://github.com/apache/arrow/issues/39848">GH-39848</a> and <a href="https://github.com/apache/arrow/issues/40376">GH-40376</a>).</li>
  <li>We no longer use internals to create Block objects and started using new pandas API with pandas version 3 <a href="https://github.com/apache/arrow/issues/35081">GH-35081</a></li>
  <li>Pandas compatibility code has been simplified as old pandas and Python versions are not supported anymore <a href="https://github.com/apache/arrow/issues/40720">GH-40720</a></li>
  <li>Deprecated <code class="language-plaintext highlighter-rouge">pyarrow.filesystem</code> legacy implementations have been removed <a href="https://github.com/apache/arrow/issues/20127">GH-20127</a></li>
</ul>

<p>New features:</p>
<ul>
  <li>Converting Arrow <code class="language-plaintext highlighter-rouge">Table</code> and <code class="language-plaintext highlighter-rouge">RecordBatch</code> to a <code class="language-plaintext highlighter-rouge">Tensor</code> (not the same as <a href="https://arrow.apache.org/docs/dev/format/CanonicalExtensions.html#official-list">tensor extension array</a>) is being developed in Arrow C++ with bindings in Python. Umbrella issue: (<a href="https://github.com/apache/arrow/issues/40058">GH-40058</a>). In current release the option to convert a <code class="language-plaintext highlighter-rouge">RecordBatch</code> to <code class="language-plaintext highlighter-rouge">Tensor</code> with <code class="language-plaintext highlighter-rouge">pyarrow.RecordBatch.to_tensor(...)</code> is added returning a row or column major tensor with an option of writing missing values as <code class="language-plaintext highlighter-rouge">NaN</code> in the result.</li>
  <li><code class="language-plaintext highlighter-rouge">ListView</code> and <code class="language-plaintext highlighter-rouge">LargeListView</code> array formats are now supported by PyArrow (<a href="https://github.com/apache/arrow/issues/39812">GH-39812</a>, <a href="https://github.com/apache/arrow/issues/39855">GH-39855</a>, <a href="https://github.com/apache/arrow/issues/40205">GH-40205</a>, <a href="https://github.com/apache/arrow/issues/41039">GH-41039</a>, <a href="https://github.com/apache/arrow/issues/40266">GH-40266</a>)</li>
  <li><code class="language-plaintext highlighter-rouge">Binary</code> and <code class="language-plaintext highlighter-rouge">StringView</code> are now supported in PyArrow (<a href="https://github.com/apache/arrow/issues/39651">GH-39651</a>, <a href="https://github.com/apache/arrow/issues/39852">GH-39852</a>, <a href="https://github.com/apache/arrow/issues/40092">GH-40092</a>)</li>
  <li>Final support for Run-End Encoded arrays in PyArrow has been included (conversion to numpy and pandas <a href="https://github.com/apache/arrow/issues/40659">GH-40659</a>, construction in <code class="language-plaintext highlighter-rouge">pa.array(...)</code> <a href="https://github.com/apache/arrow/issues/40273">GH-40273</a>)</li>
  <li><code class="language-plaintext highlighter-rouge">AsofJoinNode</code> C++ functionality is now exposed in Python as a <code class="language-plaintext highlighter-rouge">join_asof</code> <a href="https://github.com/apache/arrow/issues/34235">GH-34235</a></li>
  <li>Minimal python bindings are added for AzureFilesystem <a href="https://github.com/apache/arrow/issues/39968">GH-39968</a></li>
  <li><code class="language-plaintext highlighter-rouge">FixedSizeTensorScalar</code> class is added <a href="https://github.com/apache/arrow/issues/37484">GH-37484</a></li>
</ul>

<p>Other improvements:</p>
<ul>
  <li>Add ChunkedArray import/export to/from C <a href="https://github.com/apache/arrow/issues/39984">GH-39984</a></li>
  <li><code class="language-plaintext highlighter-rouge">pyarrow.Field</code> and <code class="language-plaintext highlighter-rouge">pyarrow.ChunkedArray</code> can now be constructed from objects supporting the PyCapsule Arrow C Data Interface <a href="https://github.com/apache/arrow/issues/38010">GH-38010</a></li>
  <li>Requested_schema is supported in <code class="language-plaintext highlighter-rouge">__arrow_c_stream__</code> implementations <a href="https://github.com/apache/arrow/issues/40066">GH-40066</a></li>
  <li>Add low-level bindings for exporting/importing the C Device Interface
 <a href="https://github.com/apache/arrow/issues/39979">GH-39979</a></li>
  <li>Function to download and extract timezone database on a Windows machine is added <a href="https://github.com/apache/arrow/issues/37328">GH-37328</a></li>
  <li>Missing methods are added to <code class="language-plaintext highlighter-rouge">pyarrow.RecordBatch</code> <a href="https://github.com/apache/arrow/issues/30915">GH-30915</a></li>
  <li>Dictionary is now also accepted in <code class="language-plaintext highlighter-rouge">pyarrow.record_batch</code> factory function (as in <code class="language-plaintext highlighter-rouge">pyarrow.table</code>) <a href="https://github.com/apache/arrow/issues/40291">GH-40291</a></li>
  <li>Usage of scalar legacy cast has been removed <a href="https://github.com/apache/arrow/issues/40023">GH-40023</a></li>
  <li>Missing byte_width attribute are added to all DataType classes <a href="https://github.com/apache/arrow/issues/39277">GH-39277</a></li>
  <li><code class="language-plaintext highlighter-rouge">FileInfo</code> instances can now be used to construct Dataset objects <a href="https://github.com/apache/arrow/issues/40142">GH-40142</a></li>
  <li>Support hashing for <code class="language-plaintext highlighter-rouge">FileMetaData</code> and <code class="language-plaintext highlighter-rouge">ParquetSchema</code> <a href="https://github.com/apache/arrow/issues/39780">GH-39780</a></li>
  <li><code class="language-plaintext highlighter-rouge">force_virtual_addressing</code> is exposed in PyArrow <a href="https://github.com/apache/arrow/issues/39779">GH-39779</a></li>
</ul>

<p>Relevant bug fixes:</p>
<ul>
  <li>Calling <code class="language-plaintext highlighter-rouge">pyarrow.dataset.ParquetFileFormat.make_write_options</code> as a class method now returns a warning <a href="https://github.com/apache/arrow/issues/39440">GH-39440</a></li>
  <li><code class="language-plaintext highlighter-rouge">ScalarMemoTable</code>is now initiated only when deduplication is enabled which fixes large memory consumption in the other case <a href="https://github.com/apache/arrow/issues/40316">GH-40316</a></li>
  <li>Slicing an array backwards beyond the start doesn’t include first item (<a href="https://github.com/apache/arrow/issues/38768">GH-38768</a> and <a href="https://github.com/apache/arrow/issues/40642">GH-40642</a>)</li>
  <li>Memory leaks when creating Arrow array from Python list of dicts is fixed <a href="https://github.com/apache/arrow/issues/37989">GH-37989</a></li>
  <li><code class="language-plaintext highlighter-rouge">FixedSizeListType</code> has not been considered as a nested type and is now added to <code class="language-plaintext highlighter-rouge">_NESTED_TYPES</code> <a href="https://github.com/apache/arrow/issues/40171">GH-40171</a></li>
  <li><code class="language-plaintext highlighter-rouge">max_chunksize</code> is now validated in <code class="language-plaintext highlighter-rouge">Table.to_batches</code> <a href="https://github.com/apache/arrow/issues/39788">GH-39788</a></li>
  <li>
    <p>Raising <code class="language-plaintext highlighter-rouge">ValueError</code> on <code class="language-plaintext highlighter-rouge">_ensure_partitioning</code>in Dataset is fixed <a href="https://github.com/apache/arrow/issues/39579">GH-39579</a></p>
  </li>
  <li>Python stacktrace is now attached to errors in <code class="language-plaintext highlighter-rouge">ConvertPyError</code> <a href="https://github.com/apache/arrow/issues/37164">GH-37164</a></li>
</ul>

<h2 id="r-notes">R notes</h2>

<ul>
  <li>Arrow IPC streams (i.e., <code class="language-plaintext highlighter-rouge">write_ipc_stream</code>) can now be written to socket
connections (<a href="https://github.com/apache/arrow/pull/38897">GH-38897</a>)</li>
  <li>The <code class="language-plaintext highlighter-rouge">print()</code> output for <code class="language-plaintext highlighter-rouge">Dataset</code> and <code class="language-plaintext highlighter-rouge">Table</code> objects has been improved so it
now shows dimensions and truncates its output in the case of wide schemas
(<a href="https://github.com/apache/arrow/pull/38917">GH-38917</a>)</li>
  <li>Various improvements and fixes to documentation, package build, and CI systems</li>
</ul>

<p>For more on what’s in the 16.0.0 R package, see the <a href="/arrow-site/docs/r/news/">R changelog</a>.</p>

<h2 id="ruby-and-c-glib-notes">Ruby and C GLib notes</h2>

<h3 id="ruby">Ruby</h3>

<ul>
  <li>Added support for customizing timestamp parsers.
<a href="https://github.com/apache/arrow/issues/40590">GH-40590</a></li>
</ul>

<h3 id="c-glib">C GLib</h3>

<ul>
  <li>Added support for time zone in <code class="language-plaintext highlighter-rouge">GArrowTimestampDataType</code>.
<a href="https://github.com/apache/arrow/issues/39702">GH-39702</a></li>
  <li>Added missing compute function options.
<a href="https://github.com/apache/arrow/issues/40402">GH-40402</a>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">GArrowSplitPatternOptions</code></li>
      <li><code class="language-plaintext highlighter-rouge">GArrowStrftimeOptions</code></li>
      <li><code class="language-plaintext highlighter-rouge">GArrowStrptimeOptions</code></li>
      <li><code class="language-plaintext highlighter-rouge">GArrowStructFieldOptions</code></li>
    </ul>
  </li>
  <li>Changed documentation generator to GI-DocGen from GTK-Doc.
<a href="https://github.com/apache/arrow/issues/39935">GH-39935</a></li>
  <li>Added <code class="language-plaintext highlighter-rouge">GArrowTimestampParser</code>.
<a href="https://github.com/apache/arrow/issues/40438">GH-40438</a></li>
  <li>Added support for customizing timestamp parsers.
<a href="https://github.com/apache/arrow/issues/40590">GH-40590</a></li>
</ul>

<h2 id="rust-notes">Rust notes</h2>

<p>The Rust projects have moved to separate repositories outside the
main Arrow monorepo. For notes on the latest release of the Rust
implementation, see the latest <a href="https://github.com/apache/arrow-rs/tags">Arrow Rust changelog</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 16.0.0 release. This covers over 3 months of development work and includes 385 resolved issues on 586 distinct commits from 119 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Community Since the 15.0.0 release, Jeffrey Vo, Jay Zhan, Bryce Mecum, Joel Lubinitsky, and Sarah Gilmore have been invited to be committers. No new members have joined the Project Management Committee (PMC). Thanks for your contributions and participation in the project! C Data Interface notes Added RegisterDeviceMemoryManager and GetDeviceMemoryManage for managing mappings between a device type and id to a memory manager (GH-40698). Added RegisterCUDADevice to register CUDA devices (GH-40698). Added ImportFromChunkedArray and ExportChunkedArray for handling Chunked Arrays in the C Stream Interface (GH-38717). Fixed an issue where string and nested types weren’t being correctly imported with DeviceArray (GH-39769). Added support for copying Arrays and RecordBatches between memory types (GH-39771). Arrow Flight RPC notes Session variable RPCs were added (GH-34865) Go: cookies can be copied to another connection to reuse existing credentials (GH-39837) Go: enable PollFlightInfo for Flight SQL clients/servers (GH-39574) Java: the JDBC driver now tries all locations the server sends it (GH-38573) Java: tweak some options to give better performance (GH-40475, GH-40039) C++ notes For C++ notes refer to the full changelog. Highlights Initial support for the Azure Blob Storage has been added (GH-18014). Arrow C++ can now be built with Emscripten (GH-37821) which lays the foundation for running Arrow C++ under WASM runtimes and eventually PyArrow as well. Arrow’s filesystem modules have been separated out into individual libraries and this change enables writing and registering custom filesystem implementations (GH-38309). Conversion from Table and RecordBatch to a Tensor (not the same as tensor extension array) is being developed. Umbrella issue is created (GH-40058) and issues connected to the RecordBatch conversion are included in this release (GH-40059, GH-40357, GH-40297, GH-40060, GH-40061 and GH-40866) which means RecordBatch can now be converted to a column or row-major two-dimensional structure. Compute Bug Fixes Fixed a potential crash when accessing the true_count property on a BooleanArray (GH-41016). Performance improvements Significantly improved performance of the take kernel on certain types of inputs (GH-40207). Enhancements Support for casting to and from half-float (float16) has been added (GH-20213). Added support for residual predicates to Swiss Join implementation (GH-20339). Expanded support to primitive filter implementation for all fixed-width primitive types and take filter implementation for all well-known fixed-width types (GH-39740). Added support for calling the binary_slice kernel on Fixed-Size Binary Arrays (GH-39231). The cast kernel now supports casting from LargeString, Binary, and LargeBinary to Dictionary (GH-39463). Fields of different decimal precision can now be used together in arithmetic operations without an explicit cast beforehand. (GH-40126). Datasets Improved backpressure handling in the Dataset Writer which can significantly reduce memory usage for some use cases (https://github.com/apache/arrow/pull/40722). Parquet Byte stream split encoding support has been added for FIXED_LEN_BYTE_ARRAY, INT32, and INT64 which enables this encoding for half-float (float16) and fixed-width decimal (GH-39978). Decoding boolean values has been made faster for a variety of cases (GH-40872). Filesystems New Features In addition to building the individual filesystem implementations as separate modules, users can now write and register custom filesystem implementations (GH-38309). A new environment variable, AWS_ENDPOINT_URL_S3, has been added which allows separately overriding the endpoint for S3 operations alone (GH-38663). Bug Fixes Fixed a bug in the S3 filesystem implementation that could cause a crash when deleting an object having duplicate forward slashes in its name (GH-38821). Fixed a bug where hash_mean could silently overflow (GH-38833). Improvements The S3 implementation now sets the content-type of directory-like objects to application/x-directory to improve compatibility with other S3 tools (GH-38794). Repeated S3Client initialization is now roughly an order of magnitude faster (GH-40299). The MemoryPoolStats implementation has been reworked to re-order loads and stores which may be an improvement for some allocation-heavy, multi-threaded applications (GH-40783). Substrait Support has been added to Substrait for a variety of Arrow types (GH-40695). substrait-cpp has been upgraded to 0.44 (GH-40695). Development Added support the mold and lld linkers for building Arrow C++ (GH-40394, GH-40400). Miscellaneous Upgraded ORC to 2.0.0 (GH-40507). Upgraded zstd to 1.5.6 (GH-40837). Upgraded google benchmark to 1.8.3 (GH-39863). Upgraded zlib 1.3.1 (GH-39876). Various ToString methods now support an optional show_metadata argument which will print metadata that may exist in nested types. (GH-39864). C# notes IPC record batch compression has been implemented GH-24834 Optional materialization of C# string arrays is now supported GH-41047 A memory leak in the C Data interface has been fixed GH-40898 Various other bug fixes and improvements. Go Notes The Golang Arrow and Parquet libraries now require Go 1.21+ (GH-40733) Bug Fixes Arrow FlightSQL Driver will now properly handle concurrent result sets instead of pulling the entire result into memory (GH-40089) FlightSQL driver will now correctly respect the DriverConfig.TLSEnabled field (GH-40097) Fixed a panic on 32-bit architectures (GH-40672) Corrected a precision loss for Decimal types when converting to JSON (GH-40693) Fixed an issue with array.RecordBuilder when using a NullType column (GH-40719) Parquet Fixed panic when writing a DeltaBinaryPacked column containing only nulls (GH-35718) Fixed a panic when writing a ListOf(DeltaBinaryPacked) field with no data (GH-39309) Arrow DATE64 types will now be properly coerced into Parquet DATE[32-bit] logical type (GH-39456) Fixed the timezone semantics for timestamp conversion from Arrow to Parquet (GH-39466) Corrected an inaccuracy with RowGroupTotalCompressedBytes and RowGroupTotalBytesWritten for Parquet file writer (GH-39870) Fixed the TotalCompressedBytes count when falling back to plain encoding if a dictionary is too large (GH-39921) Fixed a bug when reslicing a nullable dictionary in the chunked writer (GH-39925) Enhancements Arrow Users can now access the underlying MemoTable of a dictionary builder (GH-38988) Added an option to provide a string replacer for CSV writing (GH-39552) Flight: Cookies can be copied to another connection to reuse existing credentials (GH-39837) Flight: enable PollFlightInfo for Flight SQL clients/servers (GH-39574) Added the ability to create a PreparedStatement from persisted data and provided access for FlightSQL users to the PreparedStatement handle property (GH-39774 GH-39910) FlightRPC Session management extensions have been implemented (GH-40155) Parquet Can now register new compression codecs for Parquet (GH-40113) Parquet footers can be incrementally written without closing the file (GH-40630) Java notes A breaking change to support Java 9 modules has been implemented in this release. GH-39001 A new Float16 type has been added. GH-39680 Java 22 is supported. GH-40680 Various bug fixes and improvements. JavaScript notes Dates are now stored as TimestampMillisecond (GH-40892) Vectors created from typed arrays are now correctly not nullable and null counts are now correct (GH-40852) Python notes Compatibility notes: To ensure PyArrow compatibility with NumPy 2.0 umbrella issue has been closed GH-39532 with last issues included in 16.0.0 Arrow release (GH-41098, GH-39848 and GH-40376). We no longer use internals to create Block objects and started using new pandas API with pandas version 3 GH-35081 Pandas compatibility code has been simplified as old pandas and Python versions are not supported anymore GH-40720 Deprecated pyarrow.filesystem legacy implementations have been removed GH-20127 New features: Converting Arrow Table and RecordBatch to a Tensor (not the same as tensor extension array) is being developed in Arrow C++ with bindings in Python. Umbrella issue: (GH-40058). In current release the option to convert a RecordBatch to Tensor with pyarrow.RecordBatch.to_tensor(...) is added returning a row or column major tensor with an option of writing missing values as NaN in the result. ListView and LargeListView array formats are now supported by PyArrow (GH-39812, GH-39855, GH-40205, GH-41039, GH-40266) Binary and StringView are now supported in PyArrow (GH-39651, GH-39852, GH-40092) Final support for Run-End Encoded arrays in PyArrow has been included (conversion to numpy and pandas GH-40659, construction in pa.array(...) GH-40273) AsofJoinNode C++ functionality is now exposed in Python as a join_asof GH-34235 Minimal python bindings are added for AzureFilesystem GH-39968 FixedSizeTensorScalar class is added GH-37484 Other improvements: Add ChunkedArray import/export to/from C GH-39984 pyarrow.Field and pyarrow.ChunkedArray can now be constructed from objects supporting the PyCapsule Arrow C Data Interface GH-38010 Requested_schema is supported in __arrow_c_stream__ implementations GH-40066 Add low-level bindings for exporting/importing the C Device Interface GH-39979 Function to download and extract timezone database on a Windows machine is added GH-37328 Missing methods are added to pyarrow.RecordBatch GH-30915 Dictionary is now also accepted in pyarrow.record_batch factory function (as in pyarrow.table) GH-40291 Usage of scalar legacy cast has been removed GH-40023 Missing byte_width attribute are added to all DataType classes GH-39277 FileInfo instances can now be used to construct Dataset objects GH-40142 Support hashing for FileMetaData and ParquetSchema GH-39780 force_virtual_addressing is exposed in PyArrow GH-39779 Relevant bug fixes: Calling pyarrow.dataset.ParquetFileFormat.make_write_options as a class method now returns a warning GH-39440 ScalarMemoTableis now initiated only when deduplication is enabled which fixes large memory consumption in the other case GH-40316 Slicing an array backwards beyond the start doesn’t include first item (GH-38768 and GH-40642) Memory leaks when creating Arrow array from Python list of dicts is fixed GH-37989 FixedSizeListType has not been considered as a nested type and is now added to _NESTED_TYPES GH-40171 max_chunksize is now validated in Table.to_batches GH-39788 Raising ValueError on _ensure_partitioningin Dataset is fixed GH-39579 Python stacktrace is now attached to errors in ConvertPyError GH-37164 R notes Arrow IPC streams (i.e., write_ipc_stream) can now be written to socket connections (GH-38897) The print() output for Dataset and Table objects has been improved so it now shows dimensions and truncates its output in the case of wide schemas (GH-38917) Various improvements and fixes to documentation, package build, and CI systems For more on what’s in the 16.0.0 R package, see the R changelog. Ruby and C GLib notes Ruby Added support for customizing timestamp parsers. GH-40590 C GLib Added support for time zone in GArrowTimestampDataType. GH-39702 Added missing compute function options. GH-40402 GArrowSplitPatternOptions GArrowStrftimeOptions GArrowStrptimeOptions GArrowStructFieldOptions Changed documentation generator to GI-DocGen from GTK-Doc. GH-39935 Added GArrowTimestampParser. GH-40438 Added support for customizing timestamp parsers. GH-40590 Rust notes The Rust projects have moved to separate repositories outside the main Arrow monorepo. For notes on the latest release of the Rust implementation, see the latest Arrow Rust changelog.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 0.11.0 (Libraries) Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/31/adbc-0.11.0-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 0.11.0 (Libraries) Release" /><published>2024-03-31T00:00:00-04:00</published><updated>2024-03-31T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/31/adbc-0.11.0-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/31/adbc-0.11.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 0.11.0 release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/15"><strong>36
resolved issues</strong></a> from <a href="#contributors"><strong>11 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version
0.11.0.  The <strong>API specification</strong> is versioned separately and is
at version 1.1.0.</p>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-0.11.0/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>This release includes <a href="https://www.nuget.org/packages?q=apache.arrow.adbc">NuGet packages</a> for C#.</p>

<p>The Flight SQL driver supports the session options and reuse-connection URI
scheme recently added to the protocol.</p>

<p>Go packages now require Go 1.21 or later, as Go 1.20 is out of support.  The
Go drivers now use a common driver framework to make future maintenance
easier.</p>

<p>Python wheels now include debug info to help investigate bug reports.  Also,
users of the DBAPI layer will find that the driver properly reacts to
SIGINT/Control+C in more places.</p>

<p>The Snowflake driver now returns table constraints metadata.</p>

<p>The SQLite driver now supports temporary tables and more ingestion options.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.10.0..apache-arrow-adbc-0.11.0
    39	David Li
     3	Matt Topol
     2	Dewey Dunnington
     2	davidhcoe
     1	Adnan Khan
     1	Bruce Irschick
     1	Joel Lubinitsky
     1	Julian Brandrick
     1	Ruoxuan Wang
     1	Ryan Syed
     1	vleslief-ms
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>We plan for the next release to be 1.0.0.  We aim to have this out in late May
2024.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/arrow-site/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 0.11.0 release of the Apache Arrow ADBC libraries. This covers includes 36 resolved issues from 11 distinct contributors. This is a release of the libraries, which are at version 0.11.0. The API specification is versioned separately and is at version 1.1.0. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights This release includes NuGet packages for C#. The Flight SQL driver supports the session options and reuse-connection URI scheme recently added to the protocol. Go packages now require Go 1.21 or later, as Go 1.20 is out of support. The Go drivers now use a common driver framework to make future maintenance easier. Python wheels now include debug info to help investigate bug reports. Also, users of the DBAPI layer will find that the driver properly reacts to SIGINT/Control+C in more places. The Snowflake driver now returns table constraints metadata. The SQLite driver now supports temporary tables and more ingestion options. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.10.0..apache-arrow-adbc-0.11.0 39 David Li 3 Matt Topol 2 Dewey Dunnington 2 davidhcoe 1 Adnan Khan 1 Bruce Irschick 1 Joel Lubinitsky 1 Julian Brandrick 1 Ruoxuan Wang 1 Ryan Syed 1 vleslief-ms Roadmap We plan for the next release to be 1.0.0. We aim to have this out in late May 2024. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 15.0.2 Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/18/15.0.2-release/" rel="alternate" type="text/html" title="Apache Arrow 15.0.2 Release" /><published>2024-03-18T00:00:00-04:00</published><updated>2024-03-18T00:00:00-04:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/18/15.0.2-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/18/15.0.2-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 15.0.2 release.
This is mostly a bugfix release that includes <a href="https://github.com/apache/arrow/milestone/61?closed=1"><strong>8 resolved issues</strong></a>
from <a href="/arrow-site/release/15.0.2.html#contributors"><strong>7 distinct contributors</strong></a>. See the Install Page to learn how to
get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Other bugfixes and improvements have been made: we refer
you to the <a href="/arrow-site/release/15.0.2.html#changelog">complete changelog</a>.</p>

<h2 id="c-notes">C++ notes</h2>

<p>Several bug fixes, please see the full changelog for details.</p>

<p>Arrow v15.0.1 introduced a breaking ABI change due to the inclusion of <a href="https://github.com/apache/arrow/issues/39865">GH-39865</a>
this was reported and is a known issue (<a href="https://github.com/apache/arrow/issues/40604">GH-40604</a>).</p>

<h2 id="java-notes">Java notes</h2>

<p>Fixed a regression in Arrow Java v15.0.0 affecting the arrow-dataset module on Linux. The Protobuf library dependency was not statically linked properly, resulting in an undefined symbol. The regression caused the program to crash at runtime. See <a href="https://github.com/apache/arrow/issues/39919">GH-39919</a> for more details.</p>

<h2 id="python-notes">Python notes</h2>

<ul>
  <li>Fix failure in building pyarrow when using the latest Cython release (<a href="https://github.com/apache/arrow/issues/40386">GH-40386</a>)</li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 15.0.2 release. This is mostly a bugfix release that includes 8 resolved issues from 7 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Other bugfixes and improvements have been made: we refer you to the complete changelog. C++ notes Several bug fixes, please see the full changelog for details. Arrow v15.0.1 introduced a breaking ABI change due to the inclusion of GH-39865 this was reported and is a known issue (GH-40604). Java notes Fixed a regression in Arrow Java v15.0.0 affecting the arrow-dataset module on Linux. The Protobuf library dependency was not statically linked properly, resulting in an undefined symbol. The regression caused the program to crash at runtime. See GH-39919 for more details. Python notes Fix failure in building pyarrow when using the latest Cython release (GH-40386)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow 15.0.1 Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/07/15.0.1-release/" rel="alternate" type="text/html" title="Apache Arrow 15.0.1 Release" /><published>2024-03-07T00:00:00-05:00</published><updated>2024-03-07T00:00:00-05:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/07/15.0.1-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/07/15.0.1-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 15.0.1 release.
This is mostly a bugfix release that includes <a href="https://github.com/apache/arrow/milestone/60?closed=1"><strong>42 resolved issues</strong></a>
from <a href="/arrow-site/release/15.0.1.html#contributors"><strong>18 distinct contributors</strong></a>. See the Install Page to learn how to
get the libraries for your platform.</p>

<p>The release notes below are not exhaustive and only expose selected highlights
of the release. Other bugfixes and improvements have been made: we refer
you to the <a href="/arrow-site/release/15.0.1.html#changelog">complete changelog</a>.</p>

<h2 id="c-notes">C++ notes</h2>

<p>Several bug fixes, please see the full changelog for details.</p>

<p>With this patch release we introduced a breaking ABI change due to the inclusion of <a href="https://github.com/apache/arrow/issues/39865">GH-39865</a>
this was reported and is a known issue on <a href="https://github.com/apache/arrow/issues/40604">GH-40604</a>.</p>

<h2 id="python-notes">Python notes</h2>

<ul>
  <li>Fix race condition with concurrent invocation of <code class="language-plaintext highlighter-rouge">_pandas_api.is_data_frame(df)</code> (<a href="https://github.com/apache/arrow/issues/39313">GH-39313</a>)</li>
  <li>Fix leaking references to Numpy dtypes (<a href="https://github.com/apache/arrow/issues/39599">GH-39599</a>)</li>
  <li>Fix except clauses in order to be compatible with Cython 3.0.9 (<a href="https://github.com/apache/arrow/issues/40386">GH-40386</a>)</li>
  <li>Fix interpreter deadlock when using <code class="language-plaintext highlighter-rouge">GeneratorStream</code> (<a href="https://github.com/apache/arrow/issues/40004">GH-40004</a>)</li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 15.0.1 release. This is mostly a bugfix release that includes 42 resolved issues from 18 distinct contributors. See the Install Page to learn how to get the libraries for your platform. The release notes below are not exhaustive and only expose selected highlights of the release. Other bugfixes and improvements have been made: we refer you to the complete changelog. C++ notes Several bug fixes, please see the full changelog for details. With this patch release we introduced a breaking ABI change due to the inclusion of GH-39865 this was reported and is a known issue on GH-40604. Python notes Fix race condition with concurrent invocation of _pandas_api.is_data_frame(df) (GH-39313) Fix leaking references to Numpy dtypes (GH-39599) Fix except clauses in order to be compatible with Cython 3.0.9 (GH-40386) Fix interpreter deadlock when using GeneratorStream (GH-40004)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Announcing Apache Arrow DataFusion Comet</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/06/comet-donation/" rel="alternate" type="text/html" title="Announcing Apache Arrow DataFusion Comet" /><published>2024-03-06T00:00:00-05:00</published><updated>2024-03-06T00:00:00-05:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/06/comet-donation</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/03/06/comet-donation/"><![CDATA[<!--

-->

<h1 id="introduction">Introduction</h1>
<p>The Apache Arrow PMC is pleased to announce the donation of the <a href="https://github.com/apache/arrow-datafusion-comet">Comet project</a>,
a native Spark SQL Accelerator built on <a href="https://arrow.apache.org/datafusion">Apache Arrow DataFusion</a>.</p>

<p>Comet is an Apache Spark plugin that uses Apache Arrow DataFusion to
accelerate Spark workloads. It is designed as a drop-in
replacement for Spark’s JVM based SQL execution engine and offers significant
performance improvements for some workloads as shown below.</p>

<figure style="text-align: center;">
  <img src="/arrow-site/img/datafusion-comet/comet-architecture.png" width="100%" class="img-responsive" alt="Fig 1: Adaptive Arrow schema architecture overview." />
  <figcaption>
   <b>Figure 1</b>: With Comet, users interact with the same Spark ecosystem, tools
    and APIs such as Spark SQL. Queries still run through Spark's query optimizer and planner. 
    However, the execution is delegated to Comet,
    which is significantly faster and more resource efficient than a JVM based
    implementation.
</figcaption>
</figure>

<p>Comet is one of a growing class of projects that aim to accelerate Spark using
native columnar engines such as the proprietary <a href="https://www.databricks.com/product/photon">Databricks Photon Engine</a> and
open source projects <a href="https://incubator.apache.org/projects/gluten.html">Gluten</a>, <a href="https://github.com/NVIDIA/spark-rapids">Spark RAPIDS</a>, and <a href="https://github.com/kwai/blaze">Blaze</a> (also built using
DataFusion).</p>

<p>Comet was originally implemented at Apple and the engineers who worked on the
project are also significant contributors to Arrow and DataFusion. Bringing 
Comet into the Apache Software Foundation will accelerate its development and 
grow its community of contributors and users.</p>

<h1 id="get-involved">Get Involved</h1>
<p>Comet is still in the early stages of development and we would love to have you
join us and help shape the project. We are working on an initial release, and 
expect to post another update with more details at that time.</p>

<p>Before then, here are some ways to get involved:</p>

<ul>
  <li>
    <p>Learn more by visiting the <a href="https://github.com/apache/arrow-datafusion-comet">Comet project</a> page and reading the <a href="https://lists.apache.org/thread/0q1rb11jtpopc7vt1ffdzro0omblsh0s">mailing list
discussion</a> about the initial donation.</p>
  </li>
  <li>
    <p>Help us plan out the <a href="https://github.com/apache/arrow-datafusion-comet/issues/19">roadmap</a></p>
  </li>
  <li>
    <p>Try out the project and provide feedback, file issues, and contribute code.</p>
  </li>
</ul>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[Introduction The Apache Arrow PMC is pleased to announce the donation of the Comet project, a native Spark SQL Accelerator built on Apache Arrow DataFusion. Comet is an Apache Spark plugin that uses Apache Arrow DataFusion to accelerate Spark workloads. It is designed as a drop-in replacement for Spark’s JVM based SQL execution engine and offers significant performance improvements for some workloads as shown below. Figure 1: With Comet, users interact with the same Spark ecosystem, tools and APIs such as Spark SQL. Queries still run through Spark's query optimizer and planner. However, the execution is delegated to Comet, which is significantly faster and more resource efficient than a JVM based implementation. Comet is one of a growing class of projects that aim to accelerate Spark using native columnar engines such as the proprietary Databricks Photon Engine and open source projects Gluten, Spark RAPIDS, and Blaze (also built using DataFusion). Comet was originally implemented at Apple and the engineers who worked on the project are also significant contributors to Arrow and DataFusion. Bringing Comet into the Apache Software Foundation will accelerate its development and grow its community of contributors and users. Get Involved Comet is still in the early stages of development and we would love to have you join us and help shape the project. We are working on an initial release, and expect to post another update with more details at that time. Before then, here are some ways to get involved: Learn more by visiting the Comet project page and reading the mailing list discussion about the initial donation. Help us plan out the roadmap Try out the project and provide feedback, file issues, and contribute code.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Apache Arrow ADBC 0.10.0 (Libraries) Release</title><link href="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/02/22/adbc-0.10.0-release/" rel="alternate" type="text/html" title="Apache Arrow ADBC 0.10.0 (Libraries) Release" /><published>2024-02-22T00:00:00-05:00</published><updated>2024-02-22T00:00:00-05:00</updated><id>https://mathworks.github.io/arrow-site/arrow-site/blog/2024/02/22/adbc-0.10.0-release</id><content type="html" xml:base="https://mathworks.github.io/arrow-site/arrow-site/blog/2024/02/22/adbc-0.10.0-release/"><![CDATA[<!--

-->

<p>The Apache Arrow team is pleased to announce the 0.10.0 release of
the Apache Arrow ADBC libraries. This covers includes <a href="https://github.com/apache/arrow-adbc/milestone/14"><strong>31
resolved issues</strong></a> from <a href="#contributors"><strong>18 distinct contributors</strong></a>.</p>

<p>This is a release of the <strong>libraries</strong>, which are at version
0.10.0.  The <strong>API specification</strong> is versioned separately and is
at version 1.1.0.</p>

<p>The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the <a href="https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-0.10.0/CHANGELOG.md">complete changelog</a>.</p>

<h2 id="release-highlights">Release Highlights</h2>

<p>The BigQuery driver now handles large result sets, and supports passing a
scope when authenticating.  It also has better support for ARRAY types.</p>

<p>The C++ implementation now requires C++17 or later.</p>

<p>The Flight SQL driver now supports the incremental execution feature with
Flight SQL services that implement PollFlightInfo.  Also, it will reuse
credentials/cookies when creating sub-clients to fetch data.</p>

<p>The Go libraries now expose a <code class="language-plaintext highlighter-rouge">Close</code> method on <code class="language-plaintext highlighter-rouge">AdbcDatabase</code> structs; this
is a potentially breaking change.</p>

<p>The Java implementation now has Checker Framework nullness annotations.  The
driver manager interface was overhauled; this is a breaking change to the
library APIs.  The Java Flight SQL driver now supports <code class="language-plaintext highlighter-rouge">getObjects</code>.</p>

<p>The PostgreSQL driver will add the PostgreSQL type name to the field metadata
of columns of NUMERIC type.  Also, it now handles ENUM types.</p>

<p>The Python bindings now return the underlying PyArrow <code class="language-plaintext highlighter-rouge">RecordBatchReader</code> when
requested, instead of the “wrapped” reader, due to a crash.  This means that
callers will not get ADBC-wrapped exceptions from the reader.  Also, Ctrl-C
will now interrupt ADBC operations on the main thread.</p>

<p>The Snowflake driver now has much, much faster bulk ingestion speed as it now
uploads bulk Parquet files instead of using bind parameters.</p>

<h2 id="contributors">Contributors</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.9.0..apache-arrow-adbc-0.10.0
    22	David Li
     6	Dewey Dunnington
     4	James Duong
     4	Sutou Kouhei
     4	William Ayd
     4	davidhcoe
     3	Matt Topol
     2	Bruce Irschick
     2	Joel Lubinitsky
     2	Lubo Slivka
     2	Soumya D. Sanyal
     1	Anton Levakin
     1	Bryce Mecum
     1	Curt Hagenlocher
     1	Ruoxuan Wang
     1	Ryan Syed
     1	eitsupi
     1	olivroy
</code></pre></div></div>

<h2 id="roadmap">Roadmap</h2>

<p>We are planning on a 1.0.0 release of the libraries this year, either for the
next release or the release after that.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>We welcome questions and contributions from all interested.  Issues
can be filed on <a href="https://github.com/apache/arrow-adbc/issues">GitHub</a>, and questions can be directed to GitHub
or the <a href="/arrow-site/community/">Arrow mailing lists</a>.</p>]]></content><author><name>pmc</name></author><category term="release" /><summary type="html"><![CDATA[The Apache Arrow team is pleased to announce the 0.10.0 release of the Apache Arrow ADBC libraries. This covers includes 31 resolved issues from 18 distinct contributors. This is a release of the libraries, which are at version 0.10.0. The API specification is versioned separately and is at version 1.1.0. The release notes below are not exhaustive and only expose selected highlights of the release. Many other bugfixes and improvements have been made: we refer you to the complete changelog. Release Highlights The BigQuery driver now handles large result sets, and supports passing a scope when authenticating. It also has better support for ARRAY types. The C++ implementation now requires C++17 or later. The Flight SQL driver now supports the incremental execution feature with Flight SQL services that implement PollFlightInfo. Also, it will reuse credentials/cookies when creating sub-clients to fetch data. The Go libraries now expose a Close method on AdbcDatabase structs; this is a potentially breaking change. The Java implementation now has Checker Framework nullness annotations. The driver manager interface was overhauled; this is a breaking change to the library APIs. The Java Flight SQL driver now supports getObjects. The PostgreSQL driver will add the PostgreSQL type name to the field metadata of columns of NUMERIC type. Also, it now handles ENUM types. The Python bindings now return the underlying PyArrow RecordBatchReader when requested, instead of the “wrapped” reader, due to a crash. This means that callers will not get ADBC-wrapped exceptions from the reader. Also, Ctrl-C will now interrupt ADBC operations on the main thread. The Snowflake driver now has much, much faster bulk ingestion speed as it now uploads bulk Parquet files instead of using bind parameters. Contributors $ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.9.0..apache-arrow-adbc-0.10.0 22 David Li 6 Dewey Dunnington 4 James Duong 4 Sutou Kouhei 4 William Ayd 4 davidhcoe 3 Matt Topol 2 Bruce Irschick 2 Joel Lubinitsky 2 Lubo Slivka 2 Soumya D. Sanyal 1 Anton Levakin 1 Bryce Mecum 1 Curt Hagenlocher 1 Ruoxuan Wang 1 Ryan Syed 1 eitsupi 1 olivroy Roadmap We are planning on a 1.0.0 release of the libraries this year, either for the next release or the release after that. Getting Involved We welcome questions and contributions from all interested. Issues can be filed on GitHub, and questions can be directed to GitHub or the Arrow mailing lists.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" /><media:content medium="image" url="https://mathworks.github.io/arrow-site/arrow-site/img/arrow-logo_horizontal_black-txt_white-bg.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>